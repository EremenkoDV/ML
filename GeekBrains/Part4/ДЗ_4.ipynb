{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNKzG9Ze5KKh"
      },
      "source": [
        "# Урок 4. Оценка и интерпретация полученной модели. Обсуждение курсового проекта."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiuAumsk5NMu"
      },
      "source": [
        "1. **Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhqKsOQr5Z-U"
      },
      "source": [
        "Регуляризация для деревьев принятия решений. Это набор приемов к разным моделям, ограничивающий их в стремлении к переобучению.\n",
        "В семье моделей на основе деревьев принятия решений одно дерево способно выучить все данные. Это приводит к сильному переобучению. Поэтому стратегии регуляризации для них встроены в большинство популярных пакетов. Эти стратегии часто заключаются в ограничении определенных параметров дерева:\n",
        "\n",
        "Глубина дерева (max_depth) — параметр, который ограничивает максимальный рост дерева (деревья принятия решений растут в глубину). Этот параметр позволяет уменьшить переобучение, но ограничивает количество переменных для каждого конкретного листа.\n",
        "Минимальный вес листа (min_samples_leaf) — параметр, который ограничивает рост дерева, когда следующее деление листа приводит к тому, что хотя бы в одном из них слишком мало наблюдений, что делало бы его слишком специфичным.\n",
        "Также для регрессионных деревьев можно настраивать коэффициенты для линейной регуляризации, которые используются в их листах.\n",
        "\n",
        "Леса деревьев принятия решений — более сложная модель. Для нее настраиваются параметры регуляризации, которые встречаются во многих нейросетях и являются универсальными для большинства итеративных моделей обучения:\n",
        "\n",
        "Скорость обучения (learning rate) — коэффициент, который показывает, насколько подробно нужно уточнять свои результаты с каждым шагом. Если сделать его слишком низким, то понадобится больше итераций, чтобы прийти к хорошему решению. Но есть риск, что остановиться вовремя не получится, и модель выучит данные слишком подробно, что приведет к переобучению. Если же, напротив, этот параметр будет слишком высоким, модель сможет выйти на хорошую точность за меньшее количество итераций. Но ей будет сложно приблизиться к лучшему результату, и она останется недообученной.\n",
        "Отсев (dropout) — параметр, которым задается относительная часть всех данных, скрытая случайным образом во время обучения.\n",
        "Скрывая часть данных от моделей, мы отнимаем у них возможность использовать всю вариативность данных, чтоб выучить их наизусть. Слишком высокий отсев может скрыть искомую зависимость между признаками.\n",
        "\n",
        "Ранняя остановка (early stopping) — это стратегия, при которой мы возвращаемся к последней лучшей итерации в случае, если после нескольких итераций подряд точность модели на скрытых валидационных данных не улучшилась. Это универсальный метод. Чтобы его применять, нужно достаточное количество валидационных данных для обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "263-b4Mrni-R"
      },
      "source": [
        "2. **По какому принципу рассчитывается \"важность признака (feature_importance)\" в ансамблях деревьев?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CRohXsHni-R"
      },
      "source": [
        "\n",
        "Важность признака рассчитывается с учетом увеличения ошибки. Если удаление признака увеличивает ошибку в моде­ли, этот признак важен. Если - наоборот, то от этого признака можно избавиться практически без ухудшения модели.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_kaKP9039qJ"
      },
      "source": [
        "3. **Прикрепите ссылку на курсовой проект.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-YAaLg739qK"
      },
      "source": [
        "Ноутбук курсовой работы (версия для Google Colab)\n",
        "https://github.com/EremenkoDV/ML/blob/master/GeekBrains/Part4/Project/notebook9d29a1bbd4_(for_google_colab).ipynb\n",
        "\n",
        "Ноутбук курсовой работы (версия для kaggle.com)\n",
        "https://github.com/EremenkoDV/ML/blob/master/GeekBrains/Part4/Project/notebookf1d590947f%20(for%20kaggle).ipynb\n",
        "\n",
        "Сохраненные модели для заполнения NaN\n",
        "https://github.com/EremenkoDV/ML/tree/master/GeekBrains/Part4/Project/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2WBXIWT38EI"
      },
      "source": [
        "4. **Укажите, пожалуйста, ваш ник на kaggle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jeurb1M038EK"
      },
      "source": [
        "Tale Quale"
      ]
    }
  ]
}